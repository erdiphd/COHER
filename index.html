<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <script type="text/javascript" async="" src="web//analytics.js"></script>
  <script type="text/javascript" id="www-widgetapi-script" src="web/www-widgetapi.js" async=""></script>
  <script src="web/jsapi" type="text/javascript"></script>
  <script src="web/mathjax-config.js"></script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/monokai.min.css"
    crossorigin="anonymous" title="hl-light">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/monokai.min.css"
    crossorigin="anonymous" title="hl-dark" disabled>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/shell.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/dockerfile.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
  <script>hljs.initHighlightingOnLoad();</script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/latex.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/tex.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full"
    integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>



  <script type="text/javascript">
    google.load("jquery", "1.3.2");
  </script>
  <style type="text/css">
    body {
      font-family: "Titillium Web", "HelveticaNeue-Light",
        "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial,
        "Lucida Grande", sans-serif;
      font-weight: 300;
      font-size: 18px;
      margin-left: auto;
      margin-right: auto;
      width: 1100px;
    }

    h1 {
      font-weight: 300;
    }

    .disclaimerbox {
      background-color: #eee;
      border: 1px solid #eeeeee;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
      padding: 20px;
    }

    video.header-vid {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
    }

    img.header-img {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
    }

    img.rounded {
      border: 1px solid #eeeeee;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
    }

    a:link,
    a:visited {
      color: #1367a7;
      text-decoration: none;
    }

    a:hover {
      color: #208799;
    }

    td.dl-link {
      height: 160px;
      text-align: center;
      font-size: 22px;
    }

    .layered-paper-big {
      /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow: 0px 0px 1px 1px rgba(0, 0, 0, 0.35),
        /* The top layer shadow */
        5px 5px 0 0px #fff,
        /* The second layer */
        5px 5px 1px 1px rgba(0, 0, 0, 0.35),
        /* The second layer shadow */
        10px 10px 0 0px #fff,
        /* The third layer */
        10px 10px 1px 1px rgba(0, 0, 0, 0.35),
        /* The third layer shadow */
        15px 15px 0 0px #fff,
        /* The fourth layer */
        15px 15px 1px 1px rgba(0, 0, 0, 0.35),
        /* The fourth layer shadow */
        20px 20px 0 0px #fff,
        /* The fifth layer */
        20px 20px 1px 1px rgba(0, 0, 0, 0.35),
        /* The fifth layer shadow */
        25px 25px 0 0px #fff,
        /* The fifth layer */
        25px 25px 1px 1px rgba(0, 0, 0, 0.35);
      /* The fifth layer shadow */
      margin-left: 10px;
      margin-right: 45px;
    }

    .layered-paper {
      /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow: 0px 0px 1px 1px rgba(0, 0, 0, 0.35),
        /* The top layer shadow */
        5px 5px 0 0px #fff,
        /* The second layer */
        5px 5px 1px 1px rgba(0, 0, 0, 0.35),
        /* The second layer shadow */
        10px 10px 0 0px #fff,
        /* The third layer */
        10px 10px 1px 1px rgba(0, 0, 0, 0.35);
      /* The third layer shadow */
      margin-top: 5px;
      margin-left: 10px;
      margin-right: 30px;
      margin-bottom: 5px;
    }

    .vert-cent {
      position: relative;
      top: 50%;
      transform: translateY(-50%);
    }

    hr {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right,
          rgba(0, 0, 0, 0),
          rgba(0, 0, 0, 0.75),
          rgba(0, 0, 0, 0));
    }

    #authors td {
      padding-bottom: 5px;
      padding-top: 30px;
    }
  </style>

  <script type="text/javascript" src="web/hidebib.js"></script>
  <link href="web/css" rel="stylesheet" type="text/css" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link rel="icon" type="image/png" href="https://erdiphd.github.io" />
  <title>COHER</title>
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="canonical" href="https://erdiphd.github.io/coher/" />
  <meta name="referrer" content="no-referrer-when-downgrade" />

  <meta property="og:site_name" content="Relational Reinforcement Learning" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="Force-Based Hindsight Experience Prioritization" />
  <meta property="og:description"
    content="Li, Jabri, Darrell, Agrawal. Force-Based Hindsight Experience Prioritization. 2019." />
  <meta property="og:url" content="https://richardrl.github.io/relational-rl/" />
  <meta property="og:image" content="https://pathak22.github.io/modular-assemblies/resources/generalization.png" />
  <meta property="og:video" content="https://www.youtube.com/embed/nVuoxhVqBVw" />

  <meta property="article:publisher" content="https://github.com/richardrl/richardrl.github.io/" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Force-Based Hindsight Experience Prioritization" />
  <meta name="twitter:description"
    content="Li, Jabri, Darrell, Agrawal. Force-Based Hindsight Experience Prioritization. 2019." />
  <meta name="twitter:url" content="https://richardrl.github.io/relational-rl/" />
  <meta name="twitter:image" content="https://richardrl.github.io/relational-rl/resources/teaser.jpg" />
  <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Richard Li" />
  <meta name="twitter:label2" content="Filed under" />
  <meta name="twitter:data2" content="" />
  <meta name="twitter:site" content="@richardli" />
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

  <script src="web/iframe_api"></script>
  <meta name="twitter:card" content="player" />
  <meta name="twitter:image" content="https://richardrl.github.io/relational-rl/resources/teaser.jpg" />
  <meta name="twitter:player" content="https://www.youtube.com/embed/nVuoxhVqBVw" />
  <meta name="twitter:player:width" content="640" />
  <meta name="twitter:player:height" content="360" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async="" src="web/js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "UA-89486716-2");
  </script>
  <!-- 
<script>
var player, seconds = 0;
function onYouTubeIframeAPIReady() {
    console.log("player");
    player = new YT.Player('yt-embed', {
        events: {
          'onReady': onPlayerReady
        }
      });
}

function onPlayerReady(event) {
    event.target.playVideo();
}


function seek(sec){
    if(player){
        seconds += sec;
        player.seekTo(seconds, true);
    }
}</script>
 -->
</head>


<body>
  <br />
  <center>
    <span style="font-size: 44px; font-weight: bold">Coevolutionary curriculum learning for tasks with sparse
      reward</span>
  </center>
  <br />
  <table align="center" width="600px">
    <tbody>
      <tr>
        <td align="center" width="150px">
          <center>
            <span style="font-size: 22px"><a href="https://erdisayar.github.io/" target="_blank">Erdi Sayar</a></span>
          </center>
        </td>
        <td align="center" width="150px">
          <center>
            <span style="font-size: 22px"><a href="https://sites.google.com/site/giovanniiacca/" target="_blank">
                Giovanni Iacca</a></span>
          </center>
        </td>
        <td align="center" width="150px">
          <center>
            <span style="font-size: 22px"><a href="https://www.ce.cit.tum.de/air/people/prof-dr-ing-habil-alois-knoll/"
                target="_blank">Alois Knoll</a></span>
          </center>
        </td>

      </tr>
      <tr></tr>
      <tr>
        <td align="center" width="200px">
          <center>
            <span style="font-size: 20px">Technical University of Munich</span>
          </center>
        </td>
        <td align="center" width="200px">
          <center><span style="font-size: 20px">University of Trento</span></center>
        </td>
        <td align="center" width="200px">
          <center><span style="font-size: 20px">Technical University of Munich</span></center>
        </td>
      </tr>
      <tr></tr>
    </tbody>
  </table>

  <table align="center" width="700px">
    <tbody>
      <tr>
        <td align="center" width="700px">
          <center><span style="font-size: 22px">IROS 2023</span></center>
        </td>
      </tr>
      <tr></tr>
    </tbody>
  </table>

  <table align="center" width="700px">
    <tbody>
      <tr>
        <td align="center" width="200px">
          <center>
            <span style="font-size: 22px"><a href="https://arxiv.org/pdf/paper_pdf_adress.pdf">[Download
                Paper]</a></span>
          </center>
        </td>
        <td align="center" width="200px">
          <center>
            <span style="font-size: 22px"><a href="https://github.com/erdisayar/">[GitHub Code]</a></span>
          </center>
        </td>
      </tr>
      <tr></tr>
    </tbody>
  </table>
  <br />

  <table align="center" width="300px">
    <tbody>
      <tr>
        <td align="center" width="300px">
          <iframe width="768" height="512" src="web/video.html" frameborder="0" allowfullscreen=""></iframe>
        </td>
      </tr>
    </tbody>
  </table>
  <!--       <br>
 -->
  <div style="width: 800px; margin: 0 auto">
    <br />
    Sections
    <ul style="margin-top: 0px">
      <li> <b> Abstract </b> </li>
      <li> <b>Methodology </b></li>
      <li><b> Experiment </b> </li>
    </ul>
    <center>
      <h3>Abstract</h3>
    </center>
    Multi-goal reinforcement learning (RL) problems with sparse rewards are challenging task. Hindsight experience
    replay (HER) learns from failures by replacing the achieved state of failed experiences with desired goal. If
    desired goals are far away from the initial states, HER cannot explore efficiently.

    To deal with that efficiency problem, curriculum-based RL approaches decompose complex tasks into sequences of
    gradually more difficult tasks by relying on some heuristics and guide the agent to explore the environment more
    efficiently. What if an algorithm generates its own curricula in an open-ended way rather than relying on heuristic
    methods? The term <i>open-ended</i> means to create novel and increasingly complex tasks without bound. In this
    paper, we propose an extension of HER called co-evolutionary hindsight experience replay (COHER) inspired by Paired
    Open-Ended Trailblazer (POET). The generated task and agent are coupled to optimize the behavior of the agent within
    the task-agent pair. After reaching a predefined success rate, the next challenging task is generated and the agent
    leverages the skills acquired from the prior task to solve the more challenging task. COHER has been evaluated on
    various sparse reward benchmark tasks and compared with a curriculum RL "Hindsight Goal Generation" (HGG) and
    vanilla-HER. The results show that COHER consistently outperforms the state-of-the-art methods and can avoid
    obstacles without giving the algorithm explicit information about their position. Lastly, we deploy policies from
    the training results to the real Franka robot for Sim2Real. We observe that Franka robot with the final policy of
    our method can achieve the task by avoiding obstacles, whereas the other policies hit the obstacles.

    <center>
      <h3>Methodology</h3>
    </center>
    In this paper, we are working on robot manipulation tasks in an open-ended process within single run. We pair each
    environment $\mathcal{X}$ (e.g different number of obstacles) with an agent $\mathcal{Y}$ (e.g neural network) and
    optimize the behaviour of agents within environment-agent pair until it reaches the predefined success rate. After
    satisfying the success rate, a bit harder new environment $\mathcal{X'}$ (e.g more obstacles than previous one) is
    generated. Correspondingly, the algorithm continuously creates a new challenging environment originating from parent
    environment. These new challenges in the environments are en coded by the number, dimension, and position of the
    obstacles and the algorithm mutates and increase some of the parameters to create new challenging environment.
    The agent seeks to solve newly generated environments by utilizing its existing skills, which are acquired from
    previous environments. In this way, the agent transfers and adapts its existing behavior to the new environment.
    New generated environment are not added to the current population in POET if they are too hard and too easy for the
    current population. On the contrary, testing an environment in our case whether or not it is
    too hard or too easy incurs much cost due to complexity of task we have to ensure that agent attains the predefined
    success rate in the current environment before solving the next one.

    Algorithm 1 describes our method briefly. We start with a very simple environment and train it using HER
    framework. When performance is greater than or equal to the predefined success rate $\delta$, the next challenging
    environment is created and agent tries to learn the new environment with its current skills.

    <tbody>
      <tr>
        <td width="1200px">
          <center><a href="web/img/algorithm_1.png"><img src="web/img/algorithm_1.png" height="500px"></a><br></center>
        </td>
      </tr>
    </tbody>

    <center>
      <h3>Experiment</h3>
    </center>

    We conduct experiments on the MuJoCo simulation provided by OpenAI Gym and used as a standard benchmark for
    Multi-goal RL using the 7-DOF Fetch Robotic Manipulator. Two standard manipulation
    tasks such as push and pickandplace are chosen.
    The state is a vector consisting of the position, orientation, linear velocity, and angular velocity of all robot
    joints as well as the position of the cube and target object (except the obstacles). It is assumed that the task is
    accomplished if object reaches the goal within the distance set by a threshold (Eq.\ref{eq:reward_function}) and
    receives a non-negative reward $0$.
    We compare the performance of our framework against vanilla HER and HGG. For all experiments, we used Energy-based
    replay buffer prioritization. When current environment $\mathcal{X}$ performance reaches
    predefined success rate $\delta$, a bit harder next environment $\mathcal{X'}$ is generated and agent continue to
    accomplish the new one with its learned model.


    PickAndPlace(FrankaPickAndPlace-v1):
    A pick-and-place task with different environments is shown in the Fig.\ref{fig:pickandplace_env_evolution}. The
    objective is to grasp the object and bring it to the target position. The object is shown as a black box, and its
    initial position is sampled uniformly from the yellow area. The target is the red dot, which is sampled uniformly
    from the blue region, and the obstacles are colored in magenta. The taskâ€™s difficulty is gradually increased by
    adding fixed blocks to the different locations on the table, and four different environments are generated in total.
    In the first task shown in the Fig.\ref{fig:pickandplace_1}, the robot learns how to pick up the object and place it
    on the red dot. In the second shown in Fig.\ref{fig:pickandplace_2}, a 0.2m-width, 0.02m-depth, and 0.5m-height
    obstacle is placed on the other side of the robot on the table. In the third shown in Fig.\ref{fig:pickandplace_3},
    another obstacle with 0.3m width, 0.02m depth, and 0.3m height is placed. In the last shown in
    Fig.\ref{fig:pickandplace_4}, an obstacle with 0.2m width, 0.02m depth, and 0.9m height is placed in front of the
    target sampled area.



    Pushing(FetchPush-v1):
    A cube (black box) and target (red dot) are sampled uniformly from the yellow and blue areas, respectively. The
    objective is to push the cube into the target position with a clamped gripper. The task's difficulty is gradually
    increased by adding fixed obstacles to the different locations on the table, and four different environments are
    generated in total, as shown in the Fig.\ref{fig:push_env_evolution}. In the first task Fig.\ref{fig:push_1}, the
    robot learns how to push the object to the target point. In the second task Fig.\ref{fig:push_2}, the robot needs to
    adapt its learned policy from the previous task to avoid the obstacle. In the third task Fig.\ref{fig:push_3}, there
    is only a 10cm gap, and robots should push the object through this gap. Another obstacle is placed in the middle of
    the table in the fourth task in Fig.\ref{fig:push_4}, which the robot must avoid in order to reach the target
    position.

    <div class="row_mujoco_robotics">
      <div class="column_mujoco_robotics">
        <img src="web/img/fetchpush_env.png" alt="FetchPush_Env0" style="width:100%">
      </div>
      <div class="column_mujoco_robotics">
        <img src="web/img/fetchpush_env1.png" alt="FetchPush_Env1" style="width:100%">
      </div>
      <div class="column_mujoco_robotics">
        <img src="web/img/fetchpush_env2.png" alt="FetchPush_Env2" style="width:100%">
      </div>
      <div class="column_mujoco_robotics">
        <img src="web/img/fetchpush_env3.png" alt="FetchPush_Env3" style="width:100%">
      </div>
    </div>


    <div class="row_mujoco_robotics">
      <div class="column_mujoco_robotics">
        <img src="web/img/fethcpickandplace_env0.png" alt="fethcpickandplace_env0" style="width:100%">
      </div>
      <div class="column_mujoco_robotics">
        <img src="web/img/fethcpickandplace_env1.png" alt="fethcpickandplace_env1" style="width:100%">
      </div>
      <div class="column_mujoco_robotics">
        <img src="web/img/fethcpickandplace_env2.png" alt="fethcpickandplace_env2" style="width:100%">
      </div>
      <div class="column_mujoco_robotics">
        <img src="web/img/fethcpickandplace_env3.png" alt="fethcpickandplace_env3" style="width:100%">
      </div>
    </div>

    <div class="row_mujoco_robotics">
      <div class="column_mujoco_robotics">
        <img src="web/img/sim2real_obstacle_measurement.png" alt="fethcpickandplace_env0" style="width:100%">
      </div>
      <div class="column_mujoco_robotics">
        <img src="web/img/sim2real_setup.png" alt="fethcpickandplace_env1" style="width:100%">
      </div>

    </div>
  </div>

  <div class="franka_robotic_results_container">
    <div class="franka_robotic_result">
      <img src="web/img/boxplot_environments_frankapickandplace.svg" alt="fethcpickandplace_env0" style="width:100%">
    </div>
    <div class="franka_robotic_result">
      <img src="web/img/franka_pickandplace_box_plot_compare_coher_and_her.svg" alt="fethcpickandplace_env1" style="width:100%">
    </div>
    <div class="franka_robotic_result">
      <img src="web/img/frankapickandplace_complete.svg" alt="fethcpickandplace_env2" style="width:100%">
    </div>

  </div>

  <div class="franka_robotic_results_container">
    <div class="franka_robotic_result">
      <img src="web/img/fetch_push_box_plot_compare_coher_and_her.svg" alt="fethcpickandplace_env0" style="width:100%">
    </div>
    <div class="franka_robotic_result">
      <img src="web/img/boxplot_environments_fetchpush.svg" alt="fethcpickandplace_env1" style="width:100%">
    </div>
    <div class="franka_robotic_result">
      <img src="web/img/fetchpush_complete.svg" alt="fethcpickandplace_env2" style="width:100%">
    </div>

  </div>

  
  <table class="table_robotic_tasks">
    <thead>
        <tr>
            <th>FrankaPickAndPlace</th>
            <th>COHER</th>
            <th>HER</th>
        </tr>
    </thead>
    <tbody>
      <tr class="active-row">
            <td>mean</td>
            <td>53850</td>
            <td>53850</td>
        </tr>
        <tr class="active-row">
            <td>median</td>
            <td>52600</td>
            <td>52600</td>
        </tr>
        <tr class="active-row">
          <td>standard deviation</td>
          <td>294900</td>
          <td>294900</td>
      </tr>
    </tbody>
</table>

<table class="table_robotic_tasks">
  <thead>
      <tr>
          <th>FetchPush</th>
          <th>COHER</th>
          <th>HER</th>
      </tr>
  </thead>
  <tbody>
    <tr class="active-row">
          <td>mean</td>
          <td>53850</td>
          <td>53850</td>
      </tr>
      <tr class="active-row">
          <td>median</td>
          <td>52600</td>
          <td>52600</td>
      </tr>
      <tr class="active-row">
        <td>standard deviation</td>
        <td>294900</td>
        <td>294900</td>
    </tr>
  </tbody>
</table>


  </div>
  <br />

  <h3>How to run benchmarks</h3>
  <div class="highlight1">
    <pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#fd00dc">#!/bin/bash</span> <br> </br><span style="color:#0167ff">docker-compose run --rm -d -e mujoco_env=FrankaPickAndPlace-v1 -e log_tag=log/train1 -e n_epochs=200 cher</span>
  </code></pre>
  </div>

  <br />



  <br />

  <div class="sim2real_youtube_videos_row">

    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/tV8BbRbyv3k" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>

    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/nVuoxhVqBVw" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>

    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/fst53mOdC7A" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>

    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/7poD_2C3cj0" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>
    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/2r-5qgLOluY" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>
    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/jwKgE6RP5mY" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>
    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/wEM0MBC7fpc" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>
    <div class="sim2real_youtube_videos_column">
      <div class="video-container">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/jTN0m1NsJt8" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen></iframe>
      </div>
    </div>

  </div>




  <center id="sourceCode">
    <h1>Source Code and Environment</h1>
  </center>
  <div style="width:800px; margin:0 auto; text-align=center">
    We have released the PyTorch based implementation and environment on the
    Github page. Try our code!
  </div>
  <table align="center" width="900px">
    <tbody>
      <tr>
        <!-- <p style="margin-top:4px;"></p> -->
        <td width="300px" align="center">
          <span style="font-size: 28px"><a href="https://github.com/erdisayar">[GitHub]</a></span>
        </td>
      </tr>
    </tbody>
  </table>
  <br />
  <hr />

  <h1 style="text-align: center">Paper and Bibtex</h1>
  <table align="center" width="850px">
    <tbody>
      <tr>
        <td width="250px" align="left">
          <!-- <p style="margin-top:4px;"></p> -->
          <a href="https://arxiv.org/pdf/1912.11032.pdf"><img style="height: 150px"
              src="web/ICRA_PAPER_RICHARD.pdf.jpg" /></a>
          <span style="font-size: 20pt"><a href="https://arxiv.org/pdf/1912.11032.pdf">[Paper]</a>&nbsp;
            <span style="font-size: 20pt"><a href="https://arxiv.org/pdf/1912.11032.pdf">[ArXiv]</a>
            </span></span>
        </td>
        <td width="50px" align="center"></td>
        <td width="550px" align="left">
          <!-- <p style="margin-top:4px;"></p> -->
          <p style="text-align: left">
            <b><span style="font-size: 20pt">Citation</span></b><br /><span style="font-size: 6px">&nbsp;<br /></span>
            <span style="font-size: 15pt">Richard Li, Allan Jabri, Trevor Darrell, Pulkit Agrawal.
              <b>Towards Practical Multi-object Manipulation using Relational
                Reinforcement Learning.<br /></b>
              In <i>ICRA</i> 2020.</span>
          </p>
          <!-- <p style="margin-top:20px;"></p> -->
          <span style="font-size: 20pt"><a shape="rect" href="javascript:togglebib(&#39;relationalrl19_bib&#39;)"
              class="togglebib">[Bibtex]</a></span>
        </td>
      </tr>
      <tr>
        <td width="250px" align="left"></td>
        <td width="50px" align="center"></td>
        <td width="550px" align="left">
          <div class="paper" id="relationalrl19_bib">
            <pre xml:space="preserve" style="display: none">
@inproceedings{li19relationalrl,
  Author = {Li, Richard and
  Jabri, Allan and Darrell, Trevor and Agrawal, Pulkit},
  Title = {Towards Practical Multi-object Manipulation using Relational Reinforcement Learning},
  Booktitle = {arXiv preprint arXiv:XXXX},
  Year = {2019}
}</pre>
          </div>
        </td>
      </tr>
    </tbody>
  </table>
  <br />
  <hr />

  <!--     <table align=center width=800px>
      <tr><td width=800px><left> -->
  <div style="width: 800px; margin: 0 auto; text-align: left">
    <center>
      <h1>Acknowledgements</h1>
    </center>
    We acknowledge support from US Department of Defense, DARPA's Machine
    Common Sense Grant and the BAIR and BDD industrial consortia. We thank
    Amazon Web Services (AWS) for their generous support in the form of cloud
    credits. We'd like to thank Vitchyr Pong, Kristian Hartikainen, Ashvin
    Nair and other members of the BAIR lab and the Improbable AI lab for
    helpful discussions during this project.
    <a href="https://people.eecs.berkeley.edu/~pathak/">Template credit</a>.
    <!--       </left></td></tr>
    </table> -->
    <br /><br />
    <script xml:space="preserve" language="JavaScript">
      hideallbibs();
    </script>
  </div>





</body>



</html>